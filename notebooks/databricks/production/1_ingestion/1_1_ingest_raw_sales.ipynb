{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "002d0353-cfcc-404d-85f3-551afab8d7b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Este código se ejecuta en una celda de un Notebook de Databricks\n",
    "# Su única responsabilidad es crear la tabla de la Capa de Bronce (Bronze).\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. --- Configuración de la Capa de Bronce ---\n",
    "# La ruta al archivo crudo que subiste a tu \"Volume\"\n",
    "source_volume_path = \"/Volumes/workspace/tecnomundo_data_raw/uploads_raw/Reporte de ventas por articulos-2.csv\"\n",
    "\n",
    "# Definimos explícitamente el catálogo y el schema de la Capa de Bronce\n",
    "bronze_catalog = \"workspace\"\n",
    "bronze_schema = \"tecnomundo_data_raw\"\n",
    "\n",
    "print(f\"Ruta de Origen (Volume): {source_volume_path}\")\n",
    "print(f\"Schema de Destino (Bronce): {bronze_catalog}.{bronze_schema}\")\n",
    "\n",
    "\n",
    "# 2. --- Generación Dinámica del Nombre de la Tabla de Bronce ---\n",
    "# Se toma el nombre del archivo de la ruta de origen.\n",
    "file_name = Path(source_volume_path).name\n",
    "\n",
    "# Se limpia el nombre para que sea un nombre de tabla SQL válido.\n",
    "table_base_name = Path(source_volume_path).stem\n",
    "sanitized_name = re.sub(r'[\\s\\.\\-]+', '_', table_base_name).lower()\n",
    "sanitized_name = re.sub(r'[^a-zA-Z0-9_]', '', sanitized_name)\n",
    "\n",
    "# Se construye el nombre final de la tabla de Bronce.\n",
    "bronze_table_name = f\"{sanitized_name}_raw\"\n",
    "full_bronze_table_name = f\"{bronze_catalog}.{bronze_schema}.{bronze_table_name}\"\n",
    "\n",
    "print(f\"El archivo de origen es: {file_name}\")\n",
    "print(f\"El nombre de la tabla de destino (Bronce) será: {full_bronze_table_name}\")\n",
    "\n",
    "\n",
    "# 3. --- Proceso de Ingesta a la Capa de Bronce ---\n",
    "try:\n",
    "  # --- Limpieza Previa (Opcional pero recomendado) ---\n",
    "  # Se elimina la tabla si existe para asegurar que se cree desde cero.\n",
    "  print(f\"\\nAsegurando que la tabla de destino '{full_bronze_table_name}' no exista...\")\n",
    "  spark.sql(f\"DROP TABLE IF EXISTS {full_bronze_table_name}\")\n",
    "  print(\"Limpieza previa completada.\")\n",
    "\n",
    "  print(f\"\\nIniciando la lectura del archivo: {source_volume_path}\")\n",
    "  \n",
    "  df_raw = (spark.read\n",
    "            .format(\"csv\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .option(\"inferSchema\", \"true\")\n",
    "            .load(source_volume_path))\n",
    "  \n",
    "  print(\"Lectura del archivo completada exitosamente.\")\n",
    "\n",
    "  # 4. --- Saneamiento de Nombres de Columnas ---\n",
    "  # Limpiamos los nombres de las columnas ANTES de guardar para asegurar la compatibilidad.\n",
    "  print(\"\\nSaneando nombres de columnas...\")\n",
    "  df_sanitized = df_raw\n",
    "  for col in df_sanitized.columns:\n",
    "      new_col_name = col.replace('º', '').replace('Nº', 'num').replace('ñ', 'n').replace('Ñ', 'N')\n",
    "      new_col_name = re.sub(r'[\\s\\.\\-]+', '_', new_col_name)\n",
    "      new_col_name = re.sub(r'[^a-zA-Z0-9_]', '', new_col_name).lower()\n",
    "      \n",
    "      if new_col_name != col:\n",
    "          df_sanitized = df_sanitized.withColumnRenamed(col, new_col_name)\n",
    "          print(f\"  - Columna renombrada: '{col}' -> '{new_col_name}'\")\n",
    "  \n",
    "  # 5. --- Guardado en la Capa de Bronce ---\n",
    "  # Ahora guardamos el DataFrame con los nombres de columna ya limpios.\n",
    "  print(f\"\\nIniciando el guardado en la tabla de Bronce: {full_bronze_table_name}\")\n",
    "  \n",
    "  (df_sanitized.write\n",
    "   .option(\"overwriteSchema\", \"true\") # Permite que el esquema de la tabla cambie si el origen cambia.\n",
    "   .mode(\"overwrite\")\n",
    "   .saveAsTable(full_bronze_table_name))\n",
    "  \n",
    "  print(f\"¡Éxito! Los datos han sido ingestados y guardados en la tabla de Bronce '{full_bronze_table_name}'.\")\n",
    "  \n",
    "  # 6. --- Verificación ---\n",
    "  print(\"\\nMostrando una muestra de los datos cargados en la Capa de Bronce:\")\n",
    "  final_df = spark.table(full_bronze_table_name)\n",
    "  display(final_df)\n",
    "  \n",
    "  print(\"\\nEsquema de la tabla de Bronce (nombres de columna saneados):\")\n",
    "  final_df.printSchema()\n",
    "\n",
    "except Exception as e:\n",
    "  print(f\"Ocurrió un error durante el proceso de ingesta: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1_1_ingest_raw_sales",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
