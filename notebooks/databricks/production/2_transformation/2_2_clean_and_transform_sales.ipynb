{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5c15bf8-bbdf-47d0-bf11-fc6d95c77821",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Este código se ejecuta en una celda de un Notebook de Databricks\n",
    "# Su única responsabilidad es crear la tabla de la Capa de Plata (Silver).\n",
    "# Importamos las funciones y tipos necesarios de PySpark\n",
    "from pyspark.sql.functions import col, when, lit, ceil, concat_ws, expr\n",
    "from pyspark.sql.types import IntegerType, DoubleType, StringType\n",
    "import re\n",
    "from functools import reduce as py_reduce\n",
    "import operator\n",
    "\n",
    "# 1. --- Configuración de Tablas ---\n",
    "# La tabla de entrada es la que creamos en el paso de ingesta (Capa de Bronce).\n",
    "source_table = \"workspace.tecnomundo_data_raw.reporte_de_ventas_por_articulos_2_raw\"\n",
    "\n",
    "# Definimos los schemas de destino\n",
    "output_silver_schema = \"workspace.tecnomundo_data_processed\"\n",
    "quality_issues_schema = \"workspace.tecnomundo_data_reporting\"\n",
    "\n",
    "# --- Generación Dinámica de Nombres de Tabla ---\n",
    "# Se extrae el nombre base de la tabla de origen (ej: reporte_de_ventas_por_articulos_2_raw)\n",
    "source_table_base_name = source_table.split('.')[-1]\n",
    "\n",
    "# Se quita el sufijo '_raw' para obtener el nombre limpio del archivo original.\n",
    "if source_table_base_name.endswith('_raw'):\n",
    "    clean_base_name = source_table_base_name[:-4] # len('_raw') es 4\n",
    "else:\n",
    "    clean_base_name = source_table_base_name\n",
    "\n",
    "# Se construye el nombre de la tabla de salida con la nueva extensión de procesado.\n",
    "output_silver_table = f\"{output_silver_schema}.{clean_base_name}_cleaned\"\n",
    "quality_issues_table = f\"{quality_issues_schema}.{clean_base_name}_quality_issues\"\n",
    "\n",
    "\n",
    "print(f\"Tabla de Origen (Bronce): {source_table}\")\n",
    "print(f\"Tabla de Destino (Plata): {output_silver_table}\")\n",
    "print(f\"Tabla de Problemas de Calidad: {quality_issues_table}\")\n",
    "\n",
    "\n",
    "# 2. --- Lectura de la Tabla Cruda ---\n",
    "print(f\"\\nLeyendo datos desde '{source_table}'...\")\n",
    "df = spark.table(source_table)\n",
    "\n",
    "\n",
    "# 3. --- Saneamiento de Nombres y Creación de Vista Temporal ---\n",
    "# Saneamos los nombres para poder trabajar con ellos de forma segura en el resto del script.\n",
    "print(\"\\nSaneando nombres de columnas y creando una vista temporal...\")\n",
    "rename_expressions = []\n",
    "for column in df.columns:\n",
    "    new_column_name = column.replace('º', '').replace('Nº', 'num').replace('ñ', 'n').replace('Ñ', 'N')\n",
    "    new_column_name = re.sub(r'[\\s\\.\\-]+', '_', new_column_name)\n",
    "    new_column_name = re.sub(r'[^a-zA-Z0-9_]', '', new_column_name).lower()\n",
    "    rename_expressions.append(f\"`{column}` as `{new_column_name}`\")\n",
    "\n",
    "df_sanitized = df.selectExpr(*rename_expressions)\n",
    "\n",
    "# Creamos una vista temporal para trabajar sobre ella.\n",
    "df_sanitized.createOrReplaceTempView(\"ventas_sanitized_temp_view\")\n",
    "print(\"Vista temporal 'ventas_sanitized_temp_view' creada con nombres de columna limpios.\")\n",
    "\n",
    "\n",
    "# 4. --- Lógica de Limpieza y Validación de Tipos ---\n",
    "print(\"\\nIniciando el proceso de limpieza y validación de tipos...\")\n",
    "df_to_clean = spark.table(\"ventas_sanitized_temp_view\")\n",
    "\n",
    "# a) Limpieza de la columna 'fecha'\n",
    "date_formats = [\"dd-MM-yyyy\", \"M/d/yyyy\", \"yyyy-MM-dd\", \"d-M-yyyy\"]\n",
    "coalesce_expr_str = \"coalesce(\" + \", \".join([f\"try_to_timestamp(fecha, '{f}')\" for f in date_formats]) + \")\"\n",
    "df_cleaned = df_to_clean.withColumn(\"fecha_temp\", expr(coalesce_expr_str))\n",
    "df_cleaned = df_cleaned.withColumn(\"fecha_is_valid\", col(\"fecha_temp\").isNotNull())\n",
    "df_cleaned = df_cleaned.withColumn(\"fecha\", \n",
    "    when(col(\"fecha_is_valid\"), col(\"fecha_temp\"))\n",
    "    .otherwise(lit(\"1900-01-01\").cast(\"timestamp\"))\n",
    ").drop(\"fecha_temp\")\n",
    "\n",
    "# b) Limpieza de columnas numéricas\n",
    "numeric_cols = [\"cantidad\", \"precio_un_\", \"ganancia\", \"subtotal\"]\n",
    "for c in numeric_cols:\n",
    "    df_cleaned = df_cleaned.withColumn(f\"{c}_is_valid\", col(c).cast(DoubleType()).isNotNull())\n",
    "    df_cleaned = df_cleaned.withColumn(c, \n",
    "        when(col(f\"{c}_is_valid\"), ceil(col(c).cast(DoubleType())).cast(IntegerType()))\n",
    "        .otherwise(lit(0))\n",
    "    )\n",
    "\n",
    "# c) Limpieza de columnas de texto\n",
    "text_cols = [c for c in df_to_clean.columns if c not in numeric_cols and c != \"fecha\"]\n",
    "for c in text_cols:\n",
    "    df_cleaned = df_cleaned.withColumn(c, \n",
    "        when(col(c).isNull() | (col(c) == \"\"), lit(\"Sin registro\"))\n",
    "        .otherwise(col(c))\n",
    "    )\n",
    "\n",
    "print(\"Proceso de limpieza completado.\")\n",
    "\n",
    "\n",
    "# 5. --- Separación de Filas con Problemas de Calidad ---\n",
    "print(\"\\nIdentificando y separando filas con problemas de calidad...\")\n",
    "conditions = [col(f\"{c}_is_valid\") == False for c in [\"fecha\"] + numeric_cols]\n",
    "final_condition = py_reduce(operator.or_, conditions)\n",
    "\n",
    "df_quality_issues = df_cleaned.filter(final_condition)\n",
    "df_good_data = df_cleaned.filter(~final_condition)\n",
    "\n",
    "# Creamos la descripción del problema\n",
    "issue_description_cols = [when(col(f\"{c}_is_valid\") == False, lit(f\"Problema de tipo en '{c}'\")) for c in [\"fecha\"] + numeric_cols]\n",
    "df_quality_issues = df_quality_issues.withColumn(\"quality_issue_description\", concat_ws(\", \", *issue_description_cols))\n",
    "\n",
    "# Seleccionamos solo las columnas originales (ya saneadas) y la descripción del problema\n",
    "df_quality_issues_final = df_quality_issues.select(*df_to_clean.columns, \"quality_issue_description\")\n",
    "\n",
    "print(f\"Se encontraron {df_quality_issues_final.count()} filas con problemas de calidad.\")\n",
    "print(f\"Se encontraron {df_good_data.count()} filas limpias.\")\n",
    "\n",
    "\n",
    "# 6. --- Guardado de las Tablas Finales ---\n",
    "# a) Guardar la tabla con los datos limpios (Capa de Plata)\n",
    "print(f\"\\nGuardando datos limpios en la tabla de la Capa de Plata: '{output_silver_table}'...\")\n",
    "(df_good_data.select(*df_to_clean.columns) # Seleccionamos solo las columnas limpias\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .saveAsTable(output_silver_table))\n",
    "print(\"¡Tabla de la Capa de Plata guardada exitosamente!\")\n",
    "\n",
    "# b) Guardar la tabla con los problemas de calidad\n",
    "if df_quality_issues_final.count() > 0:\n",
    "    print(f\"Guardando filas con problemas en la tabla '{quality_issues_table}'...\")\n",
    "    (df_quality_issues_final.write\n",
    "     .mode(\"overwrite\")\n",
    "     .saveAsTable(quality_issues_table))\n",
    "    print(\"¡Tabla de problemas de calidad guardada exitosamente!\")\n",
    "else:\n",
    "    print(\"No se encontraron filas con problemas de calidad para guardar.\")\n",
    "\n",
    "# 7. --- Verificación Final ---\n",
    "print(\"\\nMostrando una muestra de los datos limpios (Capa de Plata):\")\n",
    "display(spark.table(output_silver_table))\n",
    "\n",
    "if df_quality_issues_final.count() > 0:\n",
    "    print(\"\\nMostrando una muestra de las filas con problemas de calidad:\")\n",
    "    display(spark.table(quality_issues_table))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2_2_clean_and_transform_sales",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
