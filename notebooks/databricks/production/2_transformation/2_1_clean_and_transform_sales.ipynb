{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5c15bf8-bbdf-47d0-bf11-fc6d95c77821",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1752706223337}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Este código se ejecuta en una celda de un Notebook de Databricks\n",
    "# Su única responsabilidad es crear la tabla de la Capa de Plata (Silver).\n",
    "# Importamos las funciones y tipos necesarios de PySpark\n",
    "from pyspark.sql.functions import col, when, lit, ceil, concat_ws, expr, upper, regexp_extract\n",
    "from pyspark.sql.types import IntegerType, DoubleType, StringType\n",
    "import re\n",
    "from functools import reduce as py_reduce\n",
    "import operator\n",
    "\n",
    "# 1. --- Configuración de Tablas ---\n",
    "source_table = \"workspace.tecnomundo_data_raw.reporte_de_ventas_por_articulos_2_raw\"\n",
    "output_silver_table = \"workspace.tecnomundo_data_processed.reporte_de_ventas_por_articulos_2_cleaned\"\n",
    "quality_issues_table = \"workspace.tecnomundo_data_reporting.reporte_de_ventas_por_articulos_2_quality_issues\"\n",
    "\n",
    "print(f\"Tabla de Origen (Bronce): {source_table}\")\n",
    "print(f\"Tabla de Destino (Plata): {output_silver_table}\")\n",
    "print(f\"Tabla de Problemas de Calidad: {quality_issues_table}\")\n",
    "\n",
    "\n",
    "# 2. --- Lectura de la Tabla Cruda ---\n",
    "print(f\"\\nLeyendo datos desde '{source_table}'...\")\n",
    "df = spark.table(source_table)\n",
    "\n",
    "\n",
    "# 3. --- Saneamiento de Nombres y Creación de Vista Temporal ---\n",
    "print(\"\\nSaneando nombres de columnas y creando una vista temporal...\")\n",
    "rename_expressions = []\n",
    "for column in df.columns:\n",
    "    new_column_name = column.replace('Nº', 'num').replace('º', '').replace('ñ', 'n').replace('Ñ', 'N')\n",
    "    new_column_name = re.sub(r'[\\s\\.\\-]+', '_', new_column_name)\n",
    "    new_column_name = re.sub(r'[^a-zA-Z0-9_]', '', new_column_name).lower()\n",
    "    rename_expressions.append(f\"`{column}` as `{new_column_name}`\")\n",
    "\n",
    "df_sanitized = df.selectExpr(*rename_expressions)\n",
    "df_sanitized.createOrReplaceTempView(\"ventas_sanitized_temp_view\")\n",
    "print(\"Vista temporal 'ventas_sanitized_temp_view' creada con nombres de columna limpios.\")\n",
    "\n",
    "\n",
    "# 4. --- Lógica de Limpieza y Validación de Tipos ---\n",
    "print(\"\\nIniciando el proceso de limpieza y validación de tipos...\")\n",
    "df_to_clean = spark.table(\"ventas_sanitized_temp_view\")\n",
    "\n",
    "# a) Limpieza de la columna 'fecha'\n",
    "date_formats = [\"dd-MM-yyyy\", \"M/d/yyyy\", \"yyyy-MM-dd\", \"d-M-yyyy\"]\n",
    "coalesce_expr_str = \"coalesce(\" + \", \".join([f\"try_to_timestamp(fecha, '{f}')\" for f in date_formats]) + \")\"\n",
    "df_cleaned = df_to_clean.withColumn(\"fecha_temp\", expr(coalesce_expr_str))\n",
    "df_cleaned = df_cleaned.withColumn(\"fecha_is_valid\", col(\"fecha_temp\").isNotNull())\n",
    "df_cleaned = df_cleaned.withColumn(\"fecha\", \n",
    "    when(col(\"fecha_is_valid\"), col(\"fecha_temp\"))\n",
    "    .otherwise(lit(\"1900-01-01\").cast(\"timestamp\"))\n",
    ").drop(\"fecha_temp\")\n",
    "\n",
    "# b) Limpieza de columnas numéricas\n",
    "numeric_cols = [\"cantidad\", \"precio_un_\", \"ganancia\", \"subtotal\"]\n",
    "for c in numeric_cols:\n",
    "    df_cleaned = df_cleaned.withColumn(f\"{c}_is_valid\", col(c).cast(DoubleType()).isNotNull())\n",
    "    df_cleaned = df_cleaned.withColumn(c, \n",
    "        when(col(f\"{c}_is_valid\"), ceil(col(c).cast(DoubleType())).cast(IntegerType()))\n",
    "        .otherwise(lit(0))\n",
    "    )\n",
    "\n",
    "# c) Limpieza de columnas de texto\n",
    "text_cols = [c for c in df_to_clean.columns if c not in numeric_cols and c != \"fecha\"]\n",
    "for c in text_cols:\n",
    "    df_cleaned = df_cleaned.withColumn(c, \n",
    "        when(col(c).isNull() | (col(c) == \"\"), lit(\"Sin registro\"))\n",
    "        .otherwise(col(c))\n",
    "    )\n",
    "\n",
    "print(\"Proceso de limpieza completado.\")\n",
    "\n",
    "\n",
    "# 5. --- Separación de Filas con Problemas de Calidad ---\n",
    "print(\"\\nIdentificando y separando filas con problemas de calidad...\")\n",
    "conditions = [col(f\"{c}_is_valid\") == False for c in [\"fecha\"] + numeric_cols]\n",
    "final_condition = py_reduce(operator.or_, conditions)\n",
    "df_quality_issues = df_cleaned.filter(final_condition)\n",
    "df_good_data = df_cleaned.filter(~final_condition)\n",
    "\n",
    "# (El resto de la lógica de separación de errores sigue igual...)\n",
    "issue_description_cols = [when(col(f\"{c}_is_valid\") == False, lit(f\"Problema de tipo en '{c}'\")) for c in [\"fecha\"] + numeric_cols]\n",
    "df_quality_issues = df_quality_issues.withColumn(\"quality_issue_description\", concat_ws(\", \", *issue_description_cols))\n",
    "df_quality_issues_final = df_quality_issues.select(*df_to_clean.columns, \"quality_issue_description\")\n",
    "print(f\"Se encontraron {df_quality_issues_final.count()} filas con problemas de calidad.\")\n",
    "print(f\"Se encontraron {df_good_data.count()} filas limpias.\")\n",
    "\n",
    "\n",
    "# 6. --- Preparación Final de la Capa de Plata (Modelado y Estandarización de Claves) ---\n",
    "print(\"\\nPreparando DataFrame final para la Capa de Plata...\")\n",
    "\n",
    "# Paso 6a: Estandarizar la clave del producto\n",
    "# Aplicamos las reglas de negocio para obtener la clave conformada.\n",
    "df_conformed = df_good_data.withColumn(\"codigo_producto_estandarizado\",\n",
    "    # Primero, convertimos todo a mayúsculas para solucionar la inconsistencia de case.\n",
    "    upper(\n",
    "        # Luego, aplicamos la lógica condicional para eliminar prefijos de caja.\n",
    "        # La expresión regular '^[A-Z]\\\\d{2}-' busca un patrón como 'A04-'.\n",
    "        when(col(\"codigo\").rlike(\"^[A-Z]\\\\d{2}-\"), regexp_extract(col(\"codigo\"), r'-([^-]*)$', 1))\n",
    "        .otherwise(col(\"codigo\"))\n",
    "    )\n",
    ")\n",
    "print(\"  - Clave de producto estandarizada (mayúsculas y sin prefijos).\")\n",
    "\n",
    "\n",
    "# Paso 6b: Definir explícitamente las columnas finales\n",
    "# Usamos la nueva clave estandarizada y eliminamos la original.\n",
    "final_silver_columns = [\n",
    "    \"fecha\",\n",
    "    \"comprobante_num\",\n",
    "    col(\"codigo_producto_estandarizado\").alias(\"codigo_producto\"), # Usamos la nueva clave estandarizada\n",
    "    \"cantidad\",\n",
    "    \"precio_un_\",\n",
    "    \"ganancia\",\n",
    "    \"subtotal\"\n",
    "]\n",
    "\n",
    "df_silver_final = df_conformed.select(final_silver_columns)\n",
    "print(\"  - Esquema final de la Capa de Plata definido y aplicado.\")\n",
    "\n",
    "\n",
    "# 7. --- Guardado de las Tablas Finales ---\n",
    "print(f\"\\nGuardando datos limpios en la tabla de la Capa de Plata: '{output_silver_table}'...\")\n",
    "(df_silver_final.write\n",
    " .mode(\"overwrite\")\n",
    " .option(\"overwriteSchema\", \"true\")\n",
    " .saveAsTable(output_silver_table))\n",
    "print(\"¡Tabla de la Capa de Plata guardada exitosamente!\")\n",
    "\n",
    "if df_quality_issues_final.count() > 0:\n",
    "    print(f\"Guardando filas con problemas en la tabla '{quality_issues_table}'...\")\n",
    "    (df_quality_issues_final.write\n",
    "     .mode(\"overwrite\")\n",
    "     .option(\"overwriteSchema\", \"true\")\n",
    "     .saveAsTable(quality_issues_table))\n",
    "    print(\"¡Tabla de problemas de calidad guardada exitosamente!\")\n",
    "else:\n",
    "    print(\"No se encontraron filas con problemas de calidad para guardar.\")\n",
    "\n",
    "# 8. --- Verificación Final ---\n",
    "print(\"\\nMostrando una muestra de los datos limpios (Capa de Plata):\")\n",
    "display(spark.table(output_silver_table))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2_1_clean_and_transform_sales",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
