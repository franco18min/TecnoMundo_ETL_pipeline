{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# # Análisis de Calidad de Datos: Productos No Encontrados\n",
    "#\n",
    "# **Autor:** Franco (franco18min@github.com)\n",
    "# **Fecha:** 2025-07-18\n",
    "#\n",
    "# ## Objetivo\n",
    "# Este notebook tiene como objetivo analizar los productos que no pudieron ser categorizados durante la ejecución del pipeline de la Capa de Oro en Databricks.\n",
    "#\n",
    "# El flujo de trabajo es el siguiente:\n",
    "# 1. Conectarse a Databricks y descargar la tabla de reporte de productos no encontrados.\n",
    "# 2. Analizar los datos con `pandas` para identificar patrones.\n",
    "# 3. Generar una lista de acción para corregir los datos en la fuente de la verdad (`Category.xlsx`).\n"
   ],
   "id": "27547312342be487"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T21:22:08.720321Z",
     "start_time": "2025-07-18T21:22:08.710474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1. Configuración e Importaciones ---\n",
    "# Se importa pandas para el análisis y sys/pathlib para poder importar nuestros módulos locales.\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Añadimos la carpeta 'src' al path de Python para poder importar nuestros módulos\n",
    "# Esto nos permite reutilizar el conector que ya hemos creado.\n",
    "project_root = Path.cwd().parent.parent.parent # Navega 3 niveles arriba desde notebooks/jupyters/data_quality_analysis\n",
    "src_path = project_root / 'src'\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "# Ahora podemos importar nuestra función para leer datos desde Databricks\n",
    "try:\n",
    "    from tecno_etl.utils.databricks_connector import get_df_from_databricks\n",
    "    print(\"Módulo 'databricks_connector' importado exitosamente.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error al importar el módulo: {e}\")\n",
    "    print(\"Asegúrate de que la estructura de carpetas es correcta y que el notebook se encuentra en la ubicación esperada.\")\n"
   ],
   "id": "d89090794b7abefd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Módulo 'databricks_connector' importado exitosamente.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ## 2. Extracción de Datos Problemáticos\n",
    "#\n",
    "# Nos conectamos a la tabla de reporte en Databricks que fue generada por el pipeline de la Capa de Oro. Esta tabla contiene la lista de `codigo_producto` que no encontraron una coincidencia en la tabla de dimensiones `category`."
   ],
   "id": "3a8632d744ebb165"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T21:22:52.761738Z",
     "start_time": "2025-07-18T21:22:26.524919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Definición de la tabla de reporte ---\n",
    "# El nombre de la tabla se deriva del nombre del archivo original.\n",
    "# Asegúrate de que coincida con el que se generó en el notebook de la Capa de Oro.\n",
    "REPORTING_CATALOG = \"workspace\"\n",
    "REPORTING_SCHEMA = \"tecnomundo_data_reporting\"\n",
    "REPORTING_TABLE = \"productos_sin_categoria\"\n",
    "\n",
    "# --- Descarga de datos ---\n",
    "print(f\"Descargando datos de la tabla de reporte: {REPORTING_CATALOG}.{REPORTING_SCHEMA}.{REPORTING_TABLE}\")\n",
    "\n",
    "df_unmatched = get_df_from_databricks(\n",
    "    catalog=REPORTING_CATALOG,\n",
    "    schema=REPORTING_SCHEMA,\n",
    "    table_name=REPORTING_TABLE\n",
    ")\n",
    "\n",
    "if df_unmatched is not None:\n",
    "    print(f\"\\n¡Éxito! Se descargaron {len(df_unmatched)} códigos de producto no encontrados.\")\n",
    "else:\n",
    "    print(\"\\nNo se pudieron descargar los datos o la tabla está vacía.\")\n"
   ],
   "id": "727987eb6107afc2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 18:22:26,532 - INFO - Intentando obtener la tabla 'workspace.tecnomundo_data_reporting.productos_sin_categoria' de Databricks...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando datos de la tabla de reporte: workspace.tecnomundo_data_reporting.productos_sin_categoria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 18:22:28,437 - INFO - ✅ ¡Conexión exitosa a Databricks!\n",
      "2025-07-18 18:22:28,437 - INFO - Ejecutando consulta: SELECT * FROM `workspace`.`tecnomundo_data_reporting`.`productos_sin_categoria`\n",
      "C:\\Users\\tc\\Desktop\\TecnoMundo_ETL_pipeline\\src\\tecno_etl\\utils\\databricks_connector.py:67: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, connection)\n",
      "2025-07-18 18:22:52,506 - INFO - ✅ Tabla 'productos_sin_categoria' cargada exitosamente con 7 filas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "¡Éxito! Se descargaron 7 códigos de producto no encontrados.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ## 3. Análisis Exploratorio\n",
    "#\n",
    "# Ahora que tenemos los datos en un DataFrame de `pandas`, podemos analizarlos para entender mejor el problema."
   ],
   "id": "ece0aa721dcabe58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T21:23:09.050756Z",
     "start_time": "2025-07-18T21:23:09.035867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if df_unmatched is not None and not df_unmatched.empty:\n",
    "    # Mostramos los primeros 10 productos no encontrados\n",
    "    print(\"--- Primeros 10 productos no encontrados ---\")\n",
    "    print(df_unmatched.head(10))\n",
    "\n",
    "    # Contamos cuántos productos únicos no se encontraron\n",
    "    unique_unmatched_count = df_unmatched['codigo_producto'].nunique()\n",
    "    print(f\"\\nNúmero total de códigos de producto únicos no encontrados: {unique_unmatched_count}\")\n",
    "\n",
    "else:\n",
    "    print(\"No hay productos no encontrados para analizar. ¡Excelente trabajo!\")"
   ],
   "id": "55aff8530566c4ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Primeros 10 productos no encontrados ---\n",
      "  codigo_producto\n",
      "0           C7912\n",
      "1         RC91102\n",
      "2          RC9199\n",
      "3         RC85607\n",
      "4            F434\n",
      "5         MO24127\n",
      "6         PC12413\n",
      "\n",
      "Número total de códigos de producto únicos no encontrados: 7\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ## 4. Conclusiones y Pasos a Seguir\n",
    "#\n",
    "# El análisis anterior nos proporciona una lista clara de los códigos de producto que faltan en nuestra tabla de verdad.\n",
    "#\n",
    "# ### Lista de Acción:\n",
    "# 1.  **Revisar la lista de códigos de producto** impresa en la celda anterior.\n",
    "# 2.  **Investigar cada código:**\n",
    "#     * ¿Es un producto nuevo que necesita ser añadido?\n",
    "#     * ¿Es un error de tipeo en el sistema de origen?\n",
    "# 3.  **Actualizar la Fuente de la Verdad:** Se ha proporcionado un archivo excel con los productos faltantes los cuales seran subidos a databricks para poder actualzar la tabla de dimensiones.\n",
    "# 4.  **Actualizar la Tabla de Dimensiones:** Ejecutar el pipeline local `run_local_ingestion.py` para recargar la tabla `category` en Databricks con los nuevos productos.\n",
    "# 5.  **Reprocesar la Capa de Oro:** Volver a ejecutar el notebook `3_1_categorize_sales.ipynb` en Databricks. En esta nueva ejecución, estos productos ahora serán categorizados correctamente."
   ],
   "id": "f6189a51ffbc227f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "63d2d10c657f23f4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
